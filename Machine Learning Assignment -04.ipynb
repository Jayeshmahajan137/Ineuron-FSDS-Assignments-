{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e2b6eff",
   "metadata": {},
   "source": [
    "Machine Learning- Assignment no. 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4f907c",
   "metadata": {},
   "source": [
    "# Q1. What are the key tasks involved in getting ready to work with machine learning modeling?\n",
    "Ans:- The key tasks involved in getting ready to work with machine learning modeling are as mentioned bellow-\n",
    "\n",
    "\n",
    "1. Data Collection:-\n",
    "\n",
    "Given the problem you want to solve, you will have to investigate and obtain data that you will use to feed your machine. The quality and quantity of information you get are very important since it will directly impact how well or badly your model will work. You may have the information in an existing database or you must create it from scratch. If it is a small project you can create a spreadsheet that will later be easily exported as a CSV file. It is also common to use the web scraping technique to automatically collect information from various sources such as APIs.\n",
    "\n",
    "\n",
    "2. Data Preperation:-\n",
    "This is a good time to visualize your data and check if there are correlations between the different characteristics that we obtained. It will be necessary to make a selection of characteristics since the ones you choose will directly impact the execution times and the results. You can also reduce dimensions by applying PCA if necessary.\n",
    "\n",
    "Additionally, you must balance the amount of data we have for each result -class- so that it is significant as the learning may be biased towards a type of response and when your model tries to generalize knowledge it will fail.\n",
    "\n",
    "You must also separate the data into two groups: one for training and the other for model evaluation which can be divided approximately in a ratio of 80/20 but it can vary depending on the case and the volume of data we have.\n",
    "\n",
    "At this stage, you can also pre-process your data by normalizing, eliminating duplicates, and making error corrections.\n",
    "\n",
    "\n",
    "3. Choose the model:-\n",
    "There are several models that you can choose according to the objective that you might have: you will use algorithms of classification, prediction, linear regression, clustering, i.e. k-means or K-Nearest Neighbor, Deep Learning, i.e Neural Networks, Bayesian, etc.\n",
    "\n",
    "There are various models to be used depending on the data you are going to process such as images, sound, text, and numerical values. \n",
    "\n",
    "\n",
    "4. Training the model:-\n",
    "You will need to train the datasets to run smoothly and see an incremental improvement in the prediction rate. Remember to initialize the weights of your model randomly -the weights are the values that multiply or affect the relationships between the inputs and outputs- which will be automatically adjusted by the selected algorithm the more you train them.\n",
    "\n",
    "\n",
    "5. Evaluation:-\n",
    "\n",
    "You will have to check the machine created against your evaluation data set that contains inputs that the model does not know and verify the precision of your already trained model. If the accuracy is less than or equal to 50%, that model will not be useful since it would be like tossing a coin to make decisions. If you reach 90% or more, you can have good confidence in the results that the model gives you.\n",
    "\n",
    "6. parameter tuning:-\n",
    "\n",
    "If during the evaluation you did not obtain good predictions and your precision is not the minimum desired, it is possible that you have overfitting -or underfitting problems and you must return to the training step before making a new configuration of parameters in your model. You can increase the number of times you iterate your training data- termed epochs. Another important parameter is the one known as the “learning rate”, which is usually a value that multiplies the gradient to gradually bring it closer to the global -or local- minimum to minimize the cost of the function.\n",
    "\n",
    "Increasing your values by 0.1 units from 0.001 is not the same as this can significantly affect the model execution time. You can also indicate the maximum error allowed for your model. You can go from taking a few minutes to hours, and even days, to train your machine. These parameters are often called Hyperparameters. This “tuning” is still more of an art than a science and will improve as you experiment. There are usually many parameters to adjust and when combined they can trigger all your options. Each algorithm has its own parameters to adjust. To name a few more, in Artificial Neural Networks (ANNs) you must define in its architecture the number of hidden layers it will have and gradually test with more or less and with how many neurons each layer. This will be a work of great effort and patience to give good results.\n",
    "\n",
    "7. Prediction:-\n",
    "\n",
    "Now ready to use your Machine Learning model inferring results in real-life scenarios.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817fd6e8",
   "metadata": {},
   "source": [
    "# Q2. What are the different forms of data used in machine learning? Give a specific example for each of\n",
    "them.\n",
    "Ans:- Different forms of data used in machine leraning are as follows-\n",
    "\n",
    "1. Numerical data:-\n",
    "\n",
    "Numerical data is any data where data points are exact numbers. Statisticians also might call numerical data, quantitative data. This data has meaning as a measurement such as house prices or as a count, such as a number of residential properties in Los Angeles or how many houses sold in the past year.\n",
    "\n",
    "Numerical data can be characterized by continuous or discrete data. Continuous data can assume any value within a range whereas discrete data has distinct values.\n",
    "\n",
    "\n",
    "2. categorical data:-\n",
    "\n",
    "\n",
    "Categorical data represents characteristics, such as a hockey player’s position, team, hometown. Categorical data can take numerical values. For example, maybe we would use 1 for the colour red and 2 for blue. But these numbers don’t have a mathematical meaning. That is, we can’t add them together or take the average.\n",
    "\n",
    "In the context of super classification, categorical data would be the class label. This would also be something like if a person is a man or woman, or property is residential or commercial.\n",
    "\n",
    "There is also something called ordinal data, which in some sense is a mix of numerical and categorical data. In ordinal data, the data still falls into categories, but those categories are ordered or ranked in some particular way. An example would be class difficulty, such as beginner, intermediate, and advanced. Those three types of classes would be a way that we could label the classes, and they have a natural order in increasing difficulty.\n",
    "\n",
    "\n",
    "3. Time series Data:-\n",
    "\n",
    "Time series data is a sequence of numbers collected at regular intervals over some period of time. It is very important, especially in particular fields like finance. Time series data has a temporal value attached to it, so this would be something like a date or a timestamp that you can look for trends in time.\n",
    "\n",
    "For example, we might measure the average number of home sales for many years. The difference of time series data and numerical data is that rather than having a bunch of numerical values that don’t have any time ordering, time-series data does have some implied ordering. There is a first data point collected and the last data point collected.\n",
    "\n",
    "\n",
    "\n",
    "4. Text data:-\n",
    "\n",
    "\n",
    "Text data is basically just words. A lot of the time the first thing that you do with text is you turn it into numbers using some interesting functions like the bag of words formulation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbd599a",
   "metadata": {},
   "source": [
    "# Q3. Distinguish:\n",
    "\n",
    "1. Numeric vs. categorical attributes\n",
    "\n",
    "2. Feature selection vs. dimensionality reduction\n",
    "\n",
    "Ans:- \n",
    "\n",
    "1. Numeric vs. categorical attributes\n",
    "\n",
    "* categorical data:-\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Categorical data refers to a data type that can be stored and identified based on the names or labels given to them. A process called matching is done, to draw out the similarities or relations between the data and then they are grouped accordingly. \n",
    "\n",
    "The data collected in the categorical form is also known as qualitative data. Each dataset can be grouped and labelled depending on their matching qualities, under only one category. This makes the categories mutual exclusive. \n",
    "\n",
    "\n",
    "There are two subtypes of categorical data namely: Nominal data and Ordinal data.\n",
    "\n",
    "Nominal data:– this is also called naming data. This is a type that names or labels the data and its characteristics are similar to a noun. Example: person’s name, gender, school name.\n",
    "Questions to gather nominal data look like:\n",
    "What is your name?\n",
    "What is your pet’s name?\n",
    "What is your gender?\n",
    "\n",
    "\n",
    "Ordinal data:– this includes data or elements of data that is ranked, ordered or used on a rating scale. You can count and order ordinal data but it doesn’t allow you to measure it.\n",
    "\n",
    "Example: seminar attendants are asked to rate their seminar experience on a scale of 1-5. Against each number, there will be options that will rate their satisfaction like “very good, good, average, bad, and very bad”.\n",
    "\n",
    "\n",
    "* Numerical data:-\n",
    "\n",
    "\n",
    "\n",
    "Numerical data refers to the data that is in the form of numbers, and not in any language or descriptive form. Often referred to as quantitative data, numerical data is collected in number form and stands different from any form of number data types due to its ability to be statistically and arithmetically calculated. \n",
    "\n",
    "\n",
    "It doesn’t involve any natural language description and is quantitative in nature and it is used to measure quantities like a person’s height, age, IQ, etc. \n",
    "\n",
    "It also has two subtypes known as Discrete data and Continuous data. \n",
    "\n",
    "Discrete data :– Discrete data is used to represent countable items. It can take both numerical and categorical forms and group them into a list. This list can be finite or infinite too. \n",
    "Discrete data basically takes countable numbers like 1, 2, 3, 4, 5, and so on. In the case of infinity, these numbers will keep going on. \n",
    "\n",
    "Example: counting sugar cubes from a jar is finite countable. But counting sugar cubes from all over the world is infinite countable.\n",
    "\n",
    "Continuous data :– As the name says, this form has data in the form of intervals. Or simply said ranges. Continuous numerical data represent measurements and their intervals fall on a number line. Hence, it doesn’t involve taking counts of the items. \n",
    "Example: in a school exam, students who scored 80%-100% come under distinction, 60%-80% have first-class and below 60% are second class. \n",
    "\n",
    "Continuous data is further divided into two categories: Interval and Ratio.\n",
    "\n",
    "Interval data: – interval data type refers to data that can be measured only along a scale at equal distances from each other. The numerical values in this data type can only undergo add and subtract operations. Example: body temperature can be measured in degree Celsius and degree Fahrenheit and neither of them can be 0.\n",
    "\n",
    "\n",
    "\n",
    "Ratio data – unlike interval data, ratio data has zero points. Being similar to interval data, zero point is the only difference they have. Example: in the body temperature, the zero point temperature can be measured in Kelvin.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Feature Selection vs Dimensionality Reduction:-\n",
    "\n",
    "\n",
    "feature selection and dimensionality reduction are grouped together. While both methods are used for reducing the number of features in a dataset, there is an important difference.\n",
    "\n",
    "Feature selection is simply selecting and excluding given features without changing them.\n",
    "\n",
    "Dimensionality reduction transforms features into a lower dimension.\n",
    "\n",
    "feature selection and dimensionality reduction techniques:-\n",
    "\n",
    "Feature Selection\n",
    "Remove features with missing values\n",
    "Remove features with low variance\n",
    "Remove highly correlated features\n",
    "Univariate feature selection\n",
    "Recursive feature elimination\n",
    "Feature selection using SelectFromModel\n",
    "\n",
    "\n",
    "Dimensionality Reduction:-\n",
    "PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f86fca",
   "metadata": {},
   "source": [
    "# Q4. Make quick notes on any two of the following:\n",
    "\n",
    "1. The histogram\n",
    "\n",
    "2. Use a scatter plot\n",
    "\n",
    "3. PCA (Personal Computer Aid)\n",
    "\n",
    "Ans:- \n",
    "\n",
    "1. Histogram:-\n",
    "\n",
    "\n",
    "A histogram is used to summarize discrete or continuous data. In other words, it provides a visual interpretation of numerical data by showing the number of data points that fall within a specified range of values (called “bins”). It is similar to a vertical bar graph. However, a histogram, unlike a vertical bar graph, shows no gaps between the bars.\n",
    "\n",
    "Parts of a Histogram:-\n",
    "\n",
    "\n",
    "The title: The title describes the information included in the histogram.\n",
    "X-axis: The X-axis are intervals that show the scale of values which the measurements fall under.\n",
    "Y-axis: The Y-axis shows the number of times that the values occurred within the intervals set by the X-axis.\n",
    "The bars: The height of the bar shows the number of times that the values occurred within the interval, while the width of the bar shows the interval that is covered. For a histogram with equal bins, the width should be the same across all bars.\n",
    "\n",
    "\n",
    "Importance of a Histogram:-\n",
    "\n",
    "\n",
    "Creating a histogram provides a visual representation of data distribution. Histograms can display a large amount of data and the frequency of the data values. The median and distribution of the data can be determined by a histogram. In addition, it can show any outliers or gaps in the data.\n",
    "\n",
    "\n",
    "\n",
    "2. Scatter plot:-\n",
    "\n",
    "A scatter plot is also called a scatter chart, scattergram, or scatter plot, XY graph. The scatter diagram graphs numerical data pairs, with one variable on each axis, show their relationship. Now the question comes for everyone: when to use a scatter plot?\n",
    "\n",
    "Scatter plots are used in either of the following situation:-\n",
    "\n",
    "When we have paired numerical data:-\n",
    "\n",
    "When there are multiple values of the dependent variable for a unique value of an independent variable\n",
    "In determining the relationship between variables in some scenarios, such as identifying potential root causes of problems, checking whether two products that appear to be related both occur with the exact cause and so on.\n",
    "Scatter Plot Uses and Examples\n",
    "Scatter plots instantly report a large volume of data. It is beneficial in the following situations –\n",
    "\n",
    "For a large set of data points given\n",
    "Each set comprises a pair of values\n",
    "The given data is in numeric form\n",
    "\n",
    "Scatter plot Correlation:-\n",
    "\n",
    "\n",
    "We know that the correlation is a statistical measure of the relationship between the two variables’ relative movements. If the variables are correlated, the points will fall along a line or curve. The better the correlation, the closer the points will touch the line. This cause examination tool is considered as one of the seven essential quality tools.\n",
    "\n",
    "Types of correlation:-\n",
    "\n",
    "\n",
    "The scatter plot explains the correlation between two attributes or variables. It represents how closely the two variables are connected. There can be three such situations to see the relation between the two variables –\n",
    "\n",
    "Positive Correlation\n",
    "Negative Correlation\n",
    "No Correlation\n",
    "\n",
    "\n",
    "\n",
    "3. PCA:-\n",
    "\n",
    "Principal Component Analysis, or PCA, is a dimensionality-reduction method that is often used to reduce the dimensionality of large data sets, by transforming a large set of variables into a smaller one that still contains most of the information in the large set.\n",
    "\n",
    "Reducing the number of variables of a data set naturally comes at the expense of accuracy, but the trick in dimensionality reduction is to trade a little accuracy for simplicity. Because smaller data sets are easier to explore and visualize and make analyzing data much easier and faster for machine learning algorithms without extraneous variables to process.\n",
    "\n",
    "So to sum up, the idea of PCA is simple — reduce the number of variables of a data set, while preserving as much information as possible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3fcdfc",
   "metadata": {},
   "source": [
    "# Q5-Why is it necessary to investigate data? Is there a discrepancy in how qualitative and quantitative data are explored?\n",
    "Ans:-\n",
    "\n",
    "Data scientists spend most of their time exploring, cleaning, and preparing their data for modeling. This helps them to build accurate models and check assumptions required for fitting models.\n",
    "\n",
    "Create meaningful data visualizations, predict future trends from the data.\n",
    "\n",
    "Ask the right questions:-\n",
    "\n",
    "\n",
    "\n",
    "Whether it’s surveying results, sales data, or an email campaign, you’ve collected data for a specific purpose. By extension, apply this purpose to the questions you’re asking of the data itself. Beginning with some specific questions can keep your research focused and allow you to see the forest through the trees. A question like “what does my revenue look like for the past 3 years” is vague and allows for exploration but also confusion.\n",
    "\n",
    "Instead, something like “which channel brings in the most revenue for the past 3 years” has a clearer answer. Subsequent questions may be: “which department brings in the most revenue per year” or “are sales in climbing gear increasing or decreasing this year?” It’s important to have a specific question in mind when you begin data analysis so as to provide some structure and avoid stumbling into false positives.\n",
    "\n",
    "\n",
    "Analyze different subset of data:-\n",
    "\n",
    "\n",
    "It’s easier to spot relationships if you analyze the data from different subsets. For example, segment your revenue data by channel like the chart above, or by the department. Experiment with the subsets and variables that make the most sense of the questions you developed in the previous step.\n",
    "\n",
    "This design focuses on allowing you to stay within your train of thought and smoothly transition from question to question, without tripping up on formatting or equations. It can also be helpful to use what would be referred to as a pivot table in Excel. In our outdoor gear retailer example, you can switch from a quarterly view to revenue by a quarter of the year just by selecting in a drop-down menu. The graph below then is an aggregate of each quarter’s revenue between 2010 and 2013.\n",
    "\n",
    "\n",
    "\n",
    "Explore trends:-\n",
    "\n",
    "\n",
    "Experiment with your time variables. Look at the quarter, month, or week, whichever makes sense based on what you’re looking for. Sometimes what is missing is also just as important as what is there. If there are holes in your data analysis, take note. It can be helpful to take notes through your analysis, reminders of what you’d like to research or discuss with colleagues later.\n",
    "\n",
    "Take a look at this quarterly analysis of revenue by the department. It’s not very helpful because it’s hard to spot trends.\n",
    "\n",
    "\n",
    "Find your blind spots\n",
    "Do you bump up against a particular question regularly? There is a fine line between collecting as much data as you can get answers, and frustrating your users with too many questions. Weigh this consideration when deciding how much data you’d like to collect. Then you can either find a way to gather that information from your users or at least write it on a data collection wish list for later discussion.\n",
    "\n",
    "Actually been collected:-\n",
    "\n",
    "\n",
    "\n",
    "for the task you are being asked to do. And you are being asked to make the\n",
    "data validate an outcome that has already been decided.\n",
    "Most organizations don’t think scientifically. They don’t create a hypothesis and then decide what data they need to collect to validate it. They choose an outcome, then make the data fit.\n",
    "Often the data come from something else entirely – often as a byproduct of a business process. Then someone has the bright idea “We could use this to work out”\n",
    "Analyzing the below graph, the graph illustrates the information about the blind spots of a data set. Hidden data will be one of the drawbacks to getting a solution. Overall, finding outliers will be a solution\n",
    "\n",
    "\n",
    "Investigate the whys:-\n",
    "\n",
    "\n",
    "After your daily, weekly, or quarterly analysis, take your charts, notes, and conclusions to the rest of the team and start trying to piece together as much as you can. The data can tell you what is happening, but not the why. The why requires piecing together the backstory. Because so many factors play into your sales data, coming together with your team to discuss insights from your data can lead to a lot more understanding. The marketing manager may know something about the third quarter’s climbing gear sales that the business analyst didn’t.\n",
    "\n",
    "Data analysis is a continual process and the best way to approach it is to try to get less and less wrong. You probably won’t ever have all the data you want or need to answer every question about your business, but you can at least push toward more answers and better decisions. This continual feedback loop (question, analyze, investigate, repeat) can be improved but will never be perfect.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fae3edb",
   "metadata": {},
   "source": [
    "# Q6. What are the various histogram shapes? What exactly are bins?\n",
    "Ans:-\n",
    "Different shapes of histogram are as explained below:-\n",
    "\n",
    "Bell-shaped:- \n",
    "\n",
    "A bell-shaped picture, shown below, usually presents a normal distribution.\n",
    "\n",
    "\n",
    "Bimodal:- \n",
    "\n",
    "A bimodal shape, shown below, has two peaks. This shape may show that the data has come from two different systems. If this shape occurs, the two sources should be separated and analyzed separately.\n",
    "\n",
    "\n",
    "Skewed right:- \n",
    "\n",
    "Some histograms will show a skewed distribution to the right, as shown below. A distribution skewed to the right is said to be positively skewed. This kind of distribution has a large number of occurrences in the lower value cells (left side) and few in the upper value cells (right side). A skewed distribution can result when data is gathered from a system with has a boundary such as zero. In other words, all the collected data has values greater than zero.\n",
    "\n",
    "\n",
    "Skewed left:- \n",
    "\n",
    "Some histograms will show a skewed distribution to the left, as shown below. A distribution skewed to the left is said to be negatively skewed. This kind of distribution has a large number of occurrences in the upper value cells (right side) and few in the lower value cells (left side). A skewed distribution can result when data is gathered from a system with a boundary such as 100. In other words, all the collected data has values less than 100.\n",
    "\n",
    "\n",
    "Uniform:-\n",
    "\n",
    "A uniform distribution, as shown below, provides little information about the system. An example would be a state lottery, in which each class has about the same number of elements. It may describe a distribution which has several modes (peaks). If your histogram has this shape, check to see if several sources of variation have been combined. If so, analyze them separately. If multiple sources of variation do not seem to be the cause of this pattern, different groupings can be tried to see if a more useful pattern results. This could be as simple as changing the starting and ending points of the cells, or changing the number of cells. A uniform distribution often means that the number of classes is too small.\n",
    "\n",
    "\n",
    "Random:-\n",
    "\n",
    "\n",
    "A random distribution, as shown below, has no apparent pattern. Like the uniform distribution, it may describe a distribution that has several modes (peaks). If your histogram has this shape, check to see if several sources of variation have been combined. If so, analyze them separately. If multiple sources of variation do not seem to be the cause of this pattern, different groupings can be tried to see if a more useful pattern results. This could be as simple as changing the starting and ending points of the cells, or changing the number of cells. A random distribution often means there are too many classes.\n",
    "\n",
    "\n",
    "Bins:-\n",
    "\n",
    "\n",
    "A bin is one of the groups of values on the horizontal axis of the histogram. Unlike a bar chart, which puts gaps between bars to separate the categories, no gaps appear between the bars of a histogram unless there are actual gaps in the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540f1351",
   "metadata": {},
   "source": [
    "# Q7. How do we deal with data outliers?\n",
    "Ans:- \n",
    "\n",
    "1. What are Outliers?\n",
    "\n",
    "We all have heard of the idiom ‘odd one out which means something unusual in comparison to the others in a group.\n",
    "\n",
    "Similarly, an Outlier is an observation in a given dataset that lies far from the rest of the observations. That means an outlier is vastly larger or smaller than the remaining values in the set.\n",
    "\n",
    "2. Why do they occur?\n",
    "\n",
    "An outlier may occur due to the variability in the data, or due to experimental error/human error.\n",
    "\n",
    "They may indicate an experimental error or heavy skewness in the data(heavy-tailed distribution).\n",
    "\n",
    "\n",
    "3. What do they affect?\n",
    "\n",
    "\n",
    "In statistics, we have three measures of central tendency namely Mean, Median, and Mode. They help us describe the data.\n",
    "\n",
    "Mean is the accurate measure to describe the data when we do not have any outliers present.\n",
    "\n",
    "Median is used if there is an outlier in the dataset.\n",
    "\n",
    "Mode is used if there is an outlier AND about ½ or more of the data is the same.\n",
    "\n",
    "‘Mean’ is the only measure of central tendency that is affected by the outliers which in turn impacts Standard deviation.\n",
    "\n",
    "Example:\n",
    "Consider a small dataset, sample= [15, 101, 18, 7, 13, 16, 11, 21, 5, 15, 10, 9]. By looking at it, one can quickly say ‘101’ is an outlier that is much larger than the other values.\n",
    "\n",
    "\n",
    "4. Detecting Outliers:-\n",
    "\n",
    "\n",
    "If our dataset is small, we can detect the outlier by just looking at the dataset. But what if we have a huge dataset, how do we identify the outliers then? We need to use visualization and mathematical techniques.\n",
    "\n",
    "Below are some of the techniques of detecting outliers\n",
    "\n",
    "Boxplots\n",
    "Z-score\n",
    "Inter Quantile Range(IQR)\n",
    "\n",
    "\n",
    "5. Handling Outliers:-\n",
    "Till now we learned about detecting the outliers. The main question is WHAT do we do with the outliers?\n",
    "\n",
    "Below are some of the methods of treating the outliers\n",
    "\n",
    "Trimming/removing the outlier\n",
    "Quantile based flooring and capping\n",
    "Mean/Median imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56efd08a",
   "metadata": {},
   "source": [
    "# Q8.What are the various central inclination measures? Why does mean vary too much from median in certain data sets?\n",
    "Ans:-\n",
    "Measures of Central Tendency\n",
    "An essential statistical concept is the “measure of central tendency“. This measure is an important way to summarize the dataset with one representative value. This measure provides a rough picture of where data points are centered. The commonly used measures of central tendency are:\n",
    "\n",
    "Mean\n",
    "Median\n",
    "Mode\n",
    "\n",
    "\n",
    "The mean (average) of a data set is found by adding all numbers in the data set and then dividing by the number of values in the set. The median is the middle value when a data set is ordered from least to greatest. The mode is the number that occurs most often in a data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a92649",
   "metadata": {},
   "source": [
    "# Q9. Describe how a scatter plot can be used to investigate bivariate relationships. Is it possible to find outliers using a scatter plot?\n",
    "Ans:-\n",
    "A bivariate data set shows a linear relationship if the scatterplot shows points bunched randomly around a straight line. The points might be tightly bunched and fall almost exactly on a line, or they might be wildly scattered, forming a cloud of points.\n",
    "\n",
    "\n",
    "A scatterplot is a useful summary of a set of bivariate data (two variables), usually drawn before working out a linear correlation coefficient or fitting a regression line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27656d2c",
   "metadata": {},
   "source": [
    "# Q10. Describe how cross-tabs can be used to figure out how two variables are related.\n",
    "Ans:-\n",
    "\n",
    "Cross tabulation is a method to quantitatively analyze the relationship between multiple variables.\n",
    "\n",
    "Also known as contingency tables or cross tabs, cross tabulation groups variables to understand the correlation between different variables. It also shows how correlations change from one variable grouping to another. It is usually used in statistical analysis to find patterns, trends, and probabilities within raw data.\n",
    "\n",
    "When you can use cross tabulation:-\n",
    "\n",
    "\n",
    "Cross tabulation is usually performed on categorical data — data that can be divided into mutually exclusive groups.\n",
    "\n",
    "An example of categorical data is the region of sales for a product. Typically, region can be divided into categories such as geographic area (North, South, Northeast, West, etc) or state (Andhra Pradesh, Rajasthan, Bihar, etc). The important thing to remember about categorical data is that a categorical data point cannot belong to more than one category.\n",
    "\n",
    "Cross tabulations are used to examine relationships within data that may not be readily apparent. Cross tabulation is especially useful for studying market research or survey responses. Cross tabulation of categorical data can be done with through tools such as SPSS, SAS, and Microsoft Excel.\n",
    "\n",
    "\n",
    "The benefits of cross tabulation:-\n",
    "\n",
    "Now that we are clear about how to use cross tabulation, let’s take a brief look at the benefits of using cross tabulation.\n",
    "\n",
    "1. Eliminates confusion while interpreting data:-\n",
    "\n",
    "\n",
    "Raw data can be difficult to interpret. Even for small data sets, it is all too easy to derive wrong results by just looking at the data. Cross tabulation offers a simple method of grouping variables, which minimizes the potential for confusion or error by providing clear results.\n",
    "\n",
    "2. Helps in deriving innumerable insights:-\n",
    "\n",
    "\n",
    "As we observed in our example, cross tabulation can help us derive great insights from raw data. These insights are not easy to see when the raw data is formatted as a table. Since cross tabulation clearly maps out relations between categorical variables, researchers can gain better and deeper insights — insights that otherwise would have been overlooked or would have taken a lot of time to decode from more complicated forms of statistical analysis.\n",
    "\n",
    "3. Offers data points to chart out a course of action:-\n",
    "\n",
    "\n",
    "\n",
    "Cross tabulation makes it easier to interpret data, which is beneficial for researchers who have limited knowledge of statistical analysis. With cross tabulation, people do not need statistical programming to correlate categorical variables. The clarity offered by cross tabulation helps professionals evaluate their current work and chart out future strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37081931",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
